{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting MFCC Features from Pathological dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import fft, dct, fftshift\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import signal\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAudio(audio, sample_rate):\n",
    "    plt.figure(figsize=(17,5))\n",
    "    plt.plot(np.linspace(0, len(audio) / sample_rate, num=len(audio)), audio)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAudioFile(filename):\n",
    "    fs, audioInput = scipy.io.wavfile.read(filename)\n",
    "    return audioInput, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preemphasis(audioInput):\n",
    "    alpha = 0.95\n",
    "    emphasized_audio = np.append(audioInput[0], audioInput[1:] - alpha * audioInput[:-1])\n",
    "    return emphasized_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frameBlocking(audio, frameSize, overlap):\n",
    "    frameSize = int(frameSize)\n",
    "    overlap = int(overlap)\n",
    "    num_frames = int(np.ceil(len(audio)/(frameSize - overlap))) \n",
    "\n",
    "    padding = ((frameSize-overlap)*num_frames) - len(audio) \n",
    "    zeros = np.zeros((padding))\n",
    "    audio = np.append(audio, zeros) \n",
    "    \n",
    "    frames = np.empty((frameSize, num_frames)) \n",
    "    start = 0\n",
    "    for i in range(num_frames):\n",
    "        frames[:,i] = audio[start:start + frameSize]\n",
    "        start = (frameSize-overlap)*i \n",
    "        \n",
    "    frames = frames.T\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyWindow(frames, frameSize):\n",
    "    \n",
    "    window = np.hamming(frameSize)\n",
    "    windowed_frames = frames * window\n",
    "    \n",
    "    return windowed_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPeriodogram(windowed_frames, frameSize, nfft):\n",
    "    audio_fft = np.absolute(fft(windowed_frames,nfft))\n",
    "    audio_fft = audio_fft[:,:nfft//2+1]\n",
    "\n",
    "    periodogram = ((1.0 / nfft) * ((audio_fft) ** 2))\n",
    "    \n",
    "    return periodogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMelFilterBank(numFilters, nfft, fs):\n",
    "    fmin_mel = 0\n",
    "    fmax_mel = (2595 * np.log10(1 + (fs // 2) / 700))\n",
    "    mel = np.linspace(fmin_mel, fmax_mel, numFilters+2)\n",
    "    hertz = (700 * (10**(mel / 2595) - 1))\n",
    "    fbins = np.floor((nfft + 1) * hertz / fs)\n",
    "    fbank = np.zeros((nfft//2+1, numFilters))\n",
    "    \n",
    "    for i in range(1,numFilters+1):\n",
    "        for k in range(int(nfft//2 + 1)):\n",
    "            if k < fbins[i-1]:\n",
    "                fbank[k, i-1] = 0\n",
    "            elif k >= fbins[i-1] and k < fbins[i]:\n",
    "                fbank[k,i-1] = (k - fbins[i-1])/(fbins[i] - fbins[i-1])\n",
    "            elif k >= fbins[i] and k < fbins[i+1]:\n",
    "                fbank[k,i-1] = (fbins[i+1] - k)/(fbins[i+1] - fbins[i])\n",
    "            else:\n",
    "                fbank[k,i-1] = 0\n",
    "    \n",
    "    return fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(periodogram, fbank):    \n",
    "    melFiltered = np.log10(np.dot(periodogram, fbank))\n",
    "    return melFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMFCC(melFiltered):\n",
    "    mel_coeff = dct(melFiltered, type=3)\n",
    "    return mel_coeff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanNormalisation(mfcc):    \n",
    "    norm_mfcc = mfcc - (np.mean(mfcc, axis=0) + 1e-8)\n",
    "    return norm_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMfcc(flag):\n",
    "    feat = np.zeros((1,48))\n",
    "    nfft = 512;\n",
    "    maxi = -1\n",
    "    numFilters = 12\n",
    "    fbank = createMelFilterBank(numFilters, nfft, 44100)\n",
    "    if(flag == 1):\n",
    "        file = open('./patient_wav_files.txt').read()\n",
    "    else:\n",
    "        file = open('./healthy_wav_files.txt').read()\n",
    "    audio_files = file.split('\\n')\n",
    "    for num, filename in enumerate(audio_files):\n",
    "        audioInput, fs = loadAudioFile(filename)\n",
    "#         highest = 202272\n",
    "        frameSize = 0.020*fs\n",
    "        overlap = (frameSize/2)\n",
    "        emphasized_audio = preemphasis(audioInput)\n",
    "        frames = frameBlocking(emphasized_audio, frameSize, overlap)\n",
    "        windowed_frames = applyWindow(frames, frameSize)\n",
    "        periodogram = findPeriodogram(windowed_frames, frameSize, nfft)\n",
    "        melFiltered = filtering(periodogram, fbank)\n",
    "        mfcc = findMFCC(melFiltered)\n",
    "        mean_normalized_mfcc = meanNormalisation(mfcc)\n",
    "#         audio_num = str(flag)+str(num)\n",
    "        mean_normalized_mfcc = np.transpose(mean_normalized_mfcc)\n",
    "#         print(mean_normalized_mfcc.shape)\n",
    "        ar = []\n",
    "        for coefficient in mean_normalized_mfcc:\n",
    "            cm = np.mean(coefficient)\n",
    "            cstd = np.std(coefficient)\n",
    "            cskew = skew(coefficient)\n",
    "            ckurtosis = kurtosis(coefficient)\n",
    "            ar.append(cm)\n",
    "            ar.extend([cstd, cskew, ckurtosis])\n",
    "#         print(len(ar))\n",
    "        feat = np.vstack((feat, ar))\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_feature_frames = extractMfcc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.99999742e-09  1.37289983e+01 -3.46911756e-02 -6.09516096e-01\n",
      " -1.00000017e-08  6.60016273e+00 -1.28049127e+00  8.69024571e-01\n",
      " -1.00000061e-08  3.79427253e+00 -4.51316841e-01 -3.73689692e-01\n",
      " -9.99999828e-09  2.43952871e+00 -3.92888530e-01 -3.81308801e-01\n",
      " -9.99999866e-09  1.23695115e+00  2.31147867e-01 -7.54066554e-01\n",
      " -1.00000000e-08  1.21293508e+00  4.18301156e-01  1.01249067e-01\n",
      " -9.99999999e-09  1.01518635e+00 -4.64846017e-01  4.59794420e-01\n",
      " -9.99999956e-09  1.27305456e+00 -2.44066203e-01 -6.42361805e-01\n",
      " -1.00000000e-08  1.02576895e+00  9.32910255e-02 -8.48627623e-02\n",
      " -1.00000001e-08  6.75608211e-01 -2.51793345e-01 -3.96230985e-01\n",
      " -9.99999993e-09  6.41277723e-01  4.06508775e-01 -1.02991111e-01\n",
      " -9.99999994e-09  6.26156737e-01 -1.51312936e-01  1.34563083e+00]\n"
     ]
    }
   ],
   "source": [
    "print(patient_feature_frames[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_feature_frames = extractMfcc(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2173, 48) (1083, 48)\n"
     ]
    }
   ],
   "source": [
    "patient_feature_frames = np.delete(patient_feature_frames, 0, 0)\n",
    "healthy_feature_frames = np.delete(healthy_feature_frames, 0, 0)\n",
    "\n",
    "# patient_feature_frames = np.delete(patient_feature_frames, 13, 1)\n",
    "# healthy_feature_frames = np.delete(healthy_feature_frames, 13, 1)\n",
    "\n",
    "print(patient_feature_frames.shape, healthy_feature_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./mfcc_features_patient.csv', patient_feature_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./mfcc_features_healthy.csv', healthy_feature_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
