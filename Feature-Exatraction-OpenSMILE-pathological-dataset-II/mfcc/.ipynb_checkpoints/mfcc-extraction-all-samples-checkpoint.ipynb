{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting MFCC Features from Pathological dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import fft, dct, fftshift\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import signal\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAudio(audio, sample_rate):\n",
    "    plt.figure(figsize=(17,5))\n",
    "    plt.plot(np.linspace(0, len(audio) / sample_rate, num=len(audio)), audio)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAudioFile(filename):\n",
    "    fs, audioInput = scipy.io.wavfile.read(filename)\n",
    "    return audioInput, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preemphasis(audioInput):\n",
    "    alpha = 0.95\n",
    "    emphasized_audio = np.append(audioInput[0], audioInput[1:] - alpha * audioInput[:-1])\n",
    "    return emphasized_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frameBlocking(audio, frameSize, overlap):\n",
    "    frameSize = int(frameSize)\n",
    "    overlap = int(overlap)\n",
    "    num_frames = int(np.ceil(len(audio)/(frameSize - overlap))) \n",
    "\n",
    "    padding = ((frameSize-overlap)*num_frames) - len(audio) \n",
    "    zeros = np.zeros((padding))\n",
    "    audio = np.append(audio, zeros) \n",
    "    \n",
    "    frames = np.empty((frameSize, num_frames)) \n",
    "    start = 0\n",
    "    for i in range(num_frames):\n",
    "        frames[:,i] = audio[start:start + frameSize]\n",
    "        start = (frameSize-overlap)*i \n",
    "        \n",
    "    frames = frames.T\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyWindow(frames, frameSize):\n",
    "    \n",
    "    window = np.hamming(frameSize)\n",
    "    windowed_frames = frames * window\n",
    "    \n",
    "    return windowed_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPeriodogram(windowed_frames, frameSize, nfft):\n",
    "    audio_fft = np.absolute(fft(windowed_frames,nfft))\n",
    "    audio_fft = audio_fft[:,:nfft//2+1]\n",
    "\n",
    "    periodogram = ((1.0 / nfft) * ((audio_fft) ** 2))\n",
    "    \n",
    "    return periodogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMelFilterBank(numFilters, nfft, fs):\n",
    "    fmin_mel = 0\n",
    "    fmax_mel = (2595 * np.log10(1 + (fs // 2) / 700))\n",
    "    mel = np.linspace(fmin_mel, fmax_mel, numFilters+2)\n",
    "    hertz = (700 * (10**(mel / 2595) - 1))\n",
    "    fbins = np.floor((nfft + 1) * hertz / fs)\n",
    "    fbank = np.zeros((nfft//2+1, numFilters))\n",
    "    \n",
    "    for i in range(1,numFilters+1):\n",
    "        for k in range(int(nfft//2 + 1)):\n",
    "            if k < fbins[i-1]:\n",
    "                fbank[k, i-1] = 0\n",
    "            elif k >= fbins[i-1] and k < fbins[i]:\n",
    "                fbank[k,i-1] = (k - fbins[i-1])/(fbins[i] - fbins[i-1])\n",
    "            elif k >= fbins[i] and k < fbins[i+1]:\n",
    "                fbank[k,i-1] = (fbins[i+1] - k)/(fbins[i+1] - fbins[i])\n",
    "            else:\n",
    "                fbank[k,i-1] = 0\n",
    "    \n",
    "    return fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(periodogram, fbank):    \n",
    "    melFiltered = np.log10(np.dot(periodogram, fbank))\n",
    "    return melFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMFCC(melFiltered):\n",
    "    mel_coeff = dct(melFiltered, type=3)\n",
    "    return mel_coeff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanNormalisation(mfcc):    \n",
    "    norm_mfcc = mfcc - (np.mean(mfcc, axis=0) + 1e-8)\n",
    "    return norm_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMfcc(flag):\n",
    "    all_frames = np.empty((1,13))\n",
    "    nfft = 512;\n",
    "    maxi = -1\n",
    "    numFilters = 12\n",
    "    fbank = createMelFilterBank(numFilters, nfft, 44100)\n",
    "    if(flag == 1):\n",
    "        file = open('./patient_wav_files.txt').read()\n",
    "    else:\n",
    "        file = open('./healthy_wav_files.txt').read()\n",
    "    audio_files = file.split('\\n')\n",
    "    for filename in audio_files:\n",
    "        audioInput, fs = loadAudioFile(filename)\n",
    "#         highest = 202272\n",
    "        frameSize = 0.020*fs\n",
    "        overlap = (frameSize/2)\n",
    "        emphasized_audio = preemphasis(audioInput)\n",
    "        frames = frameBlocking(emphasized_audio, frameSize, overlap)\n",
    "        windowed_frames = applyWindow(frames, frameSize)\n",
    "        periodogram = findPeriodogram(windowed_frames, frameSize, nfft)\n",
    "        melFiltered = filtering(periodogram, fbank)\n",
    "        mfcc = findMFCC(melFiltered)\n",
    "        mean_normalized_mfcc = meanNormalisation(mfcc)\n",
    "        for features in mean_normalized_mfcc:\n",
    "            features = np.append(features, flag)\n",
    "            all_frames = np.vstack((all_frames,features))\n",
    "    return all_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_feature_frames = extractMfcc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_feature_frames = extractMfcc(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144655, 12) (55933, 12)\n"
     ]
    }
   ],
   "source": [
    "patient_feature_frames = np.delete(patient_feature_frames, 0, 0)\n",
    "healthy_feature_frames = np.delete(healthy_feature_frames, 0, 0)\n",
    "\n",
    "patient_feature_frames = np.delete(patient_feature_frames, 12, 1)\n",
    "healthy_feature_frames = np.delete(healthy_feature_frames, 12, 1)\n",
    "\n",
    "print(patient_feature_frames.shape, healthy_feature_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./mfcc_features_patient.txt', patient_feature_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./mfcc_features_healthy.txt', healthy_feature_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
